from fastapi import FastAPI, Request, HTTPException, Depends, status, UploadFile, File
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from sqlalchemy import create_engine
from sqlalchemy.orm import Session
from sqlalchemy.orm import sessionmaker
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.models import Base, User, SearchHistory
from app.schemas import UserCreate, UserLogin, SearchRequest, ChatRequest, ChatResponse
from app.retriever import Retriever
from app.llm import LLM
# from app.zhipu_ai import ZhipuAI  # Removed to fix deployment issues
from app.config import Config
import jwt
from datetime import datetime, timedelta
from typing import Optional

# æ•°æ®åº“é…ç½® - ä½¿ç”¨å†…å­˜æ•°æ®åº“é€‚é…Vercel
DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///./block_trade_dt.db")
engine = create_engine(DATABASE_URL, connect_args={"check_same_thread": False})
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# åˆ›å»ºæ•°æ®åº“è¡¨
Base.metadata.create_all(bind=engine)

# åˆå§‹åŒ–æ™ºè°±AIï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ä»¥é¿å…å¯åŠ¨æ—¶é”™è¯¯ï¼‰
zhipu_ai = None

def get_zhipu_ai():
    # Disabled to fix deployment issues
    return None

app = FastAPI(title="Block Trade DT", description="å¤§å®—äº¤æ˜“æ•°æ®æ£€ç´¢å¹³å°")

# é™æ€æ–‡ä»¶å’Œæ¨¡æ¿
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if os.path.exists("static"):
        app.mount("/static", StaticFiles(directory="static"), name="static")
        logger.info("âœ… é™æ€æ–‡ä»¶ç›®å½•å·²æŒ‚è½½")
    else:
        logger.warning("âš ï¸  é™æ€æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨")
    
    if os.path.exists("templates"):
        templates = Jinja2Templates(directory="templates")
        logger.info("âœ… æ¨¡æ¿ç›®å½•å·²åŠ è½½")
    else:
        logger.warning("âš ï¸  æ¨¡æ¿ç›®å½•ä¸å­˜åœ¨")
        templates = None
except Exception as e:
    logger.error(f"âŒ åˆå§‹åŒ–é™æ€æ–‡ä»¶æˆ–æ¨¡æ¿å¤±è´¥: {e}")
    templates = None

# å®‰å…¨é…ç½®
security = HTTPBearer()

# åˆå§‹åŒ–æ£€ç´¢å™¨å’ŒLLMï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ä»¥é¿å…å¯åŠ¨æ—¶é”™è¯¯ï¼‰
retriever = None
llm = None

def get_retriever():
    global retriever
    if retriever is None:
        try:
            retriever = Retriever()
        except Exception as e:
            print(f"Retrieveråˆå§‹åŒ–å¤±è´¥: {e}")
            retriever = None
    return retriever

def get_llm():
    global llm
    if llm is None:
        try:
            llm = LLM()
        except Exception as e:
            print(f"LLMåˆå§‹åŒ–å¤±è´¥: {e}")
            llm = None
    return llm

# ä¾èµ–é¡¹
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security), db: Session = Depends(get_db)):
    try:
        payload = jwt.decode(credentials.credentials, Config.get_jwt_secret_key(), algorithms=["HS256"])
        username: str = payload.get("sub")
        if username is None:
            raise HTTPException(status_code=401, detail="Invalid authentication credentials")
    except jwt.PyJWTError:
        raise HTTPException(status_code=401, detail="Invalid authentication credentials")
    
    user = db.query(User).filter(User.username == username).first()
    if user is None:
        raise HTTPException(status_code=401, detail="User not found")
    return user

def get_current_user_optional(credentials: Optional[HTTPAuthorizationCredentials] = Depends(HTTPBearer(auto_error=False)), db: Session = Depends(get_db)):
    """è·å–å½“å‰ç”¨æˆ·ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœæœªæä¾›tokenåˆ™è¿”å›None"""
    if credentials is None:
        return None
    try:
        payload = jwt.decode(credentials.credentials, Config.get_jwt_secret_key(), algorithms=["HS256"])
        username: str = payload.get("sub")
        if username is None:
            return None
    except jwt.PyJWTError:
        return None
    
    user = db.query(User).filter(User.username == username).first()
    return user

# å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "Block Trade DT"}

# ä¸»é¡µè·¯ç”±
@app.get("/", response_class=HTMLResponse)
async def read_root(request: Request):
    if templates is None:
        return HTMLResponse("<h1>Block Trade DT API</h1><p>æ¨¡æ¿ç³»ç»ŸæœªåŠ è½½ï¼Œè¯·ä½¿ç”¨ API ç«¯ç‚¹</p>")
    return templates.TemplateResponse("index_v2.html", {"request": request})

# è¶‹åŠ¿é¡µé¢ï¼ˆæ·±è‰²æ¨¡å¼ï¼‰
@app.get("/trends", response_class=HTMLResponse)
async def trends_page(request: Request):
    if templates is None:
        return HTMLResponse("<h1>Trends</h1><p>æ¨¡æ¿ç³»ç»ŸæœªåŠ è½½</p>")
    return templates.TemplateResponse("trends_dark.html", {"request": request})

# æ–°é—»é¡µé¢
@app.get("/news", response_class=HTMLResponse)
async def news_page(request: Request):
    if templates is None:
        return HTMLResponse("<h1>News</h1><p>æ¨¡æ¿ç³»ç»ŸæœªåŠ è½½</p>")
    return templates.TemplateResponse("news.html", {"request": request})

# ç ”æŠ¥æ‘˜è¦é¡µé¢
@app.get("/report", response_class=HTMLResponse)
async def report_summarizer_page(request: Request):
    if templates is None:
        return HTMLResponse("<h1>ç ”æŠ¥æ‘˜è¦ç”Ÿæˆå™¨</h1><p>æ¨¡æ¿ç³»ç»ŸæœªåŠ è½½</p>")
    return templates.TemplateResponse("report_summarizer.html", {"request": request})

# APIè·¯ç”±
@app.post("/api/register")
async def register(user_data: UserCreate, db: Session = Depends(get_db)):
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²å­˜åœ¨
    existing_user = db.query(User).filter(
        (User.username == user_data.username) | (User.email == user_data.email)
    ).first()
    
    if existing_user:
        raise HTTPException(status_code=400, detail="Username or email already registered")
    
    # åˆ›å»ºæ–°ç”¨æˆ·
    user = User(
        username=user_data.username,
        email=user_data.email,
        full_name=user_data.full_name
    )
    user.set_password(user_data.password)
    
    db.add(user)
    db.commit()
    db.refresh(user)
    
    return {"message": "User registered successfully", "user_id": user.id}

@app.post("/api/login")
async def login(user_data: UserLogin, db: Session = Depends(get_db)):
    user = db.query(User).filter(User.username == user_data.username).first()
    
    if not user or not user.check_password(user_data.password):
        raise HTTPException(status_code=401, detail="Invalid username or password")
    
    # ç”ŸæˆJWT token
    access_token_expires = timedelta(hours=24)
    access_token = jwt.encode(
        {"sub": user.username, "exp": datetime.utcnow() + access_token_expires},
        Config.get_jwt_secret_key(),
        algorithm="HS256"
    )
    
    return {"access_token": access_token, "token_type": "bearer", "user": {"username": user.username, "email": user.email}}

@app.get("/api/user/profile")
async def get_user_profile(current_user: User = Depends(get_current_user)):
    return {"username": current_user.username, "email": current_user.email, "full_name": current_user.full_name}

@app.post("/api/search")
async def search(request: SearchRequest, db: Session = Depends(get_db), current_user: Optional[User] = Depends(get_current_user_optional)):
    try:
        # è·å–æ£€ç´¢å™¨å’ŒLLM
        retriever_instance = get_retriever()
        llm_instance = get_llm()
        
        if retriever_instance is None:
            raise HTTPException(status_code=503, detail="æ£€ç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•")
        
        # æ‰§è¡Œæœç´¢
        results = retriever_instance.search(request.query)
        
        # ç”Ÿæˆæ‘˜è¦
        summary = ""
        if llm_instance:
            try:
                summary = llm_instance.generate_summary(request.query, results)
            except Exception as e:
                print(f"ç”Ÿæˆæ‘˜è¦å¤±è´¥: {e}")
                summary = f"æ‰¾åˆ° {len(results)} æ¡ç›¸å…³ç»“æœ"
        else:
            summary = f"æ‰¾åˆ° {len(results)} æ¡ç›¸å…³ç»“æœ"
        
        # è®°å½•æœç´¢å†å²ï¼ˆå¦‚æœç”¨æˆ·å·²ç™»å½•ï¼‰
        if current_user:
            search_history = SearchHistory(
                user_id=current_user.id,
                query=request.query,
                results_count=len(results)
            )
            db.add(search_history)
            db.commit()
        
        return {
            "query": request.query,
            "results": results,
            "summary": summary,
            "timestamp": datetime.now().isoformat()
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/news/latest")
async def api_news_latest(limit: int = 6):
    """è·å–æœ€æ–°æ–°é—»APIï¼ˆç”¨äºé¦–é¡µå±•ç¤ºï¼‰"""
    import random
    from datetime import timedelta
    
    news_titles = [
        "Aè‚¡å¸‚åœºå¤§å®—äº¤æ˜“æ´»è·ƒåº¦åˆ›å†å²æ–°é«˜",
        "é’¢æä»·æ ¼æŒç»­ä¸Šæ¶¨ï¼Œå¸‚åœºä¾›éœ€å…³ç³»ç´§å¼ ",
        "æœ‰è‰²é‡‘å±æ¿å—é¢†æ¶¨ï¼Œé“œä»·çªç ´å†å²æ–°é«˜",
        "å›½å®¶å‘æ”¹å§”å‘å¸ƒå¤§å®—å•†å“ä»·æ ¼è°ƒæ§æ–°æ”¿ç­–",
        "2024å¹´å¤§å®—äº¤æ˜“å¸‚åœºåˆ†ææŠ¥å‘Šå‡ºç‚‰",
        "è¯ç›‘ä¼šä¼˜åŒ–å¤§å®—äº¤æ˜“åˆ¶åº¦ï¼Œæå‡å¸‚åœºæ•ˆç‡"
    ]
    
    news_summaries = [
        "è¿‘æœŸAè‚¡å¸‚åœºå¤§å®—äº¤æ˜“æ´»è·ƒåº¦æ˜¾è‘—æå‡ï¼Œå•æ—¥æˆäº¤é¢çªç ´100äº¿å…ƒå¤§å…³...",
        "å—ä¾›åº”é“¾ç´§å¼ å’Œéœ€æ±‚å¢é•¿åŒé‡å½±å“ï¼Œè¿‘æœŸé’¢æä»·æ ¼æŒç»­ä¸Šæ¶¨...",
        "æœ‰è‰²é‡‘å±æ¿å—è¡¨ç°å¼ºåŠ²ï¼Œé“œä»·çªç ´å†å²æ–°é«˜ï¼Œä¸“å®¶å»ºè®®å…³æ³¨...",
        "å›½å®¶å‘æ”¹å§”å‡ºå°æ–°æ”¿ç­–ï¼ŒåŠ å¼ºå¤§å®—å•†å“ä»·æ ¼ç›‘ç®¡ï¼Œç»´æŠ¤å¸‚åœºç§©åº...",
        "æƒå¨æœºæ„å‘å¸ƒå¹´åº¦å¤§å®—äº¤æ˜“å¸‚åœºåˆ†ææŠ¥å‘Šï¼Œè¯¦ç»†è§£è¯»å¸‚åœºè¶‹åŠ¿...",
        "è¯ç›‘ä¼šå‘å¸ƒé€šçŸ¥ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–å¤§å®—äº¤æ˜“åˆ¶åº¦ï¼Œç®€åŒ–äº¤æ˜“æµç¨‹..."
    ]
    
    news_urls = [
        "https://finance.sina.com.cn/stock/marketresearch/",
        "https://www.eastmoney.com/",
        "https://finance.qq.com/",
        "https://www.ndrc.gov.cn/",
        "https://www.caixin.com/",
        "https://www.csrc.gov.cn/"
    ]
    
    sources = ["æ–°æµªè´¢ç»", "ä¸œæ–¹è´¢å¯Œç½‘", "è…¾è®¯è´¢ç»", "å›½å®¶å‘æ”¹å§”", "è´¢æ–°ç½‘", "è¯ç›‘ä¼š"]
    
    news_list = []
    for i in range(min(limit, len(news_titles))):
        time_delta = random.randint(i * 10, i * 30)
        news_time = datetime.now() - timedelta(minutes=time_delta)
        
        news_item = {
            "id": f"latest_{i + 1}",
            "title": news_titles[i],
            "summary": news_summaries[i],
            "source": sources[i],
            "time": news_time.strftime("%Y-%m-%d %H:%M"),
            "url": news_urls[i]
        }
        news_list.append(news_item)
    
    return news_list

@app.post("/api/chat", response_model=ChatResponse)
async def chat_with_ai(chat_request: ChatRequest):
    try:
        from app.llm import LLM
        
        # ä½¿ç”¨æœ¬åœ°LLM
        llm = LLM()
        
        # è·å–æ¶ˆæ¯ï¼Œç¡®ä¿ä¸ä¸ºç©º
        message = chat_request.message if chat_request.message else ""
        
        # å¦‚æœæ¶ˆæ¯æ˜¯ç©ºçš„ï¼Œè¿”å›å‹å¥½çš„æç¤º
        if not message or not message.strip():
            return ChatResponse(
                response="æ‚¨å¥½ï¼æˆ‘æ˜¯Block Trade DTçš„AIåŠ©æ‰‹ã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨ï¼š\n1. æŸ¥è¯¢å¸‚åœºæ•°æ®\n2. åˆ†æå¸‚åœºè¶‹åŠ¿\n3. è§£ç­”äº¤æ˜“ç›¸å…³é—®é¢˜\n4. ç”Ÿæˆç ”æŠ¥æ‘˜è¦\n\nè¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œæˆ‘å°†ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚",
                timestamp=datetime.now().isoformat(),
                success=True
            )
        
        # ä½¿ç”¨æœ¬åœ°AIå›å¤é€»è¾‘ï¼ˆæ€»æ˜¯å¯ç”¨çš„fallbackï¼‰
        try:
            response = generate_local_ai_response(message)
            
            # å¦‚æœé…ç½®äº†AIå®¢æˆ·ç«¯ï¼Œå°è¯•ä½¿ç”¨GLM-4.5-Flashï¼ˆä½†ç¡®ä¿æœ‰fallbackï¼‰
            if llm.client:
                try:
                    ai_response = llm.chat(
                        message,
                        context=chat_request.conversation_history if chat_request.conversation_history else None,
                        system_prompt=chat_request.system_prompt if chat_request.system_prompt else None,
                        enable_thinking=chat_request.enable_thinking if chat_request.enable_thinking is not None else True,
                        stream=chat_request.stream if chat_request.stream is not None else False
                    )
                    # åªæœ‰åœ¨è¿”å›æœ‰æ•ˆå†…å®¹æ—¶æ‰ä½¿ç”¨AIå›å¤
                    if ai_response and ai_response.strip() and "æš‚æ—¶ä¸å¯ç”¨" not in ai_response and "æ£€æŸ¥APIå¯†é’¥" not in ai_response:
                        response = ai_response
                except Exception as e:
                    logger.warning(f"AIå®¢æˆ·ç«¯è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°å›å¤: {e}")
                    import traceback
                    logger.warning(traceback.format_exc())
                    # ç»§ç»­ä½¿ç”¨æœ¬åœ°å›å¤
        
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›å¤å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            response = "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶é‡åˆ°é”™è¯¯ã€‚è¯·ç¨åé‡è¯•æˆ–å°è¯•å…¶ä»–é—®é¢˜ã€‚"
        
        return ChatResponse(
            response=response,
            timestamp=datetime.now().isoformat(),
            success=True
        )
    except Exception as e:
        import traceback
        logger.error(f"Chat APIé”™è¯¯: {e}")
        logger.error(traceback.format_exc())
        # ç¡®ä¿æ€»æ˜¯è¿”å›æœ‰æ•ˆçš„å“åº”
        try:
            return ChatResponse(
                response=f"æŠ±æ­‰ï¼ŒAIæœåŠ¡é‡åˆ°é—®é¢˜: {str(e)}ã€‚è¯·ç¨åé‡è¯•æˆ–è”ç³»ç®¡ç†å‘˜ã€‚",
                timestamp=datetime.now().isoformat(),
                success=False
            )
        except:
            # æœ€åçš„fallbackï¼Œç¡®ä¿APIä¸ä¼šå´©æºƒ
            return JSONResponse(
                content={
                    "response": "AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                    "timestamp": datetime.now().isoformat(),
                    "success": False
                },
                status_code=200
            )

def generate_local_ai_response(message: str) -> str:
    """ç”Ÿæˆæœ¬åœ°AIå›å¤"""
    message_lower = message.lower()
    
    # å…³é”®è¯åŒ¹é…å›å¤
    if any(kw in message_lower for kw in ['ä»·æ ¼', 'æŠ¥ä»·', 'å”®ä»·']):
        return "æ ¹æ®å½“å‰å¸‚åœºæ•°æ®ï¼Œå¤§å®—å•†å“ä»·æ ¼æ³¢åŠ¨è¾ƒå¤§ã€‚å»ºè®®å…³æ³¨å®æ—¶è¡Œæƒ…å’Œå¸‚åœºåŠ¨æ€ã€‚æ‚¨å¯ä»¥è®¿é—®'å¸‚åœºæ•°æ®'é¡µé¢æŸ¥çœ‹æœ€æ–°ä»·æ ¼ä¿¡æ¯ã€‚"
    
    elif any(kw in message_lower for kw in ['è¶‹åŠ¿', 'èµ°åŠ¿', 'é¢„æµ‹']):
        return "å¸‚åœºè¶‹åŠ¿åˆ†ææ˜¾ç¤ºï¼Œå½“å‰å¤§å®—äº¤æ˜“å¸‚åœºæ•´ä½“ä¿æŒç¨³å®šã€‚å»ºè®®å…³æ³¨'è¶‹åŠ¿å›¾è¡¨'é¡µé¢è·å–è¯¦ç»†çš„è¶‹åŠ¿åˆ†ææ•°æ®ã€‚"
    
    elif any(kw in message_lower for kw in ['æ–°é—»', 'èµ„è®¯', 'åŠ¨æ€']):
        return "æœ€æ–°å¸‚åœºèµ„è®¯å·²æ›´æ–°åœ¨'å®æ—¶èµ„è®¯'é¡µé¢ã€‚æ‚¨å¯ä»¥æŸ¥çœ‹æœ€æ–°çš„è¡Œä¸šåŠ¨æ€å’Œæ”¿ç­–è§£è¯»ã€‚"
    
    elif any(kw in message_lower for kw in ['çº¸æµ†', 'æµ†æ–™', 'çº¸æµ†å¸‚åœº']):
        return "çº¸æµ†å¸‚åœºæ–¹é¢ï¼Œæ ¹æ®æœ€æ–°æ•°æ®æ˜¾ç¤ºï¼Œé’ˆå¶æœ¨æµ†å’Œé˜”å¶æœ¨æµ†ä»·æ ¼ç›¸å¯¹ç¨³å®šã€‚å»ºè®®å…³æ³¨ä¸Šæ¸¸åŸææ–™ä»·æ ¼å˜åŒ–å¯¹å¸‚åœºçš„å½±å“ã€‚æ‚¨å¯ä»¥è®¿é—®ç›¸å…³é¡µé¢æŸ¥çœ‹è¯¦ç»†æ•°æ®ã€‚"
    
    elif any(kw in message_lower for kw in ['ä½ å¥½', 'hello', 'å¸®åŠ©', 'help']):
        return "æ‚¨å¥½ï¼æˆ‘æ˜¯Block Trade DTçš„AIåŠ©æ‰‹ã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨ï¼š\n1. æŸ¥è¯¢å¸‚åœºæ•°æ®\n2. åˆ†æå¸‚åœºè¶‹åŠ¿\n3. è§£ç­”äº¤æ˜“ç›¸å…³é—®é¢˜\n\nè¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ"
    
    elif any(kw in message_lower for kw in ['ç ”æŠ¥', 'æŠ¥å‘Š', 'æ‘˜è¦']):
        return "æ‚¨å¯ä»¥ä½¿ç”¨'ç ”æŠ¥æ‘˜è¦'åŠŸèƒ½ï¼Œä¸Šä¼ 5000å­—ä»¥å†…çš„è¡Œä¸šç ”æŠ¥ï¼Œç³»ç»Ÿå°†åœ¨8ç§’å†…ä¸ºæ‚¨ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦ï¼ŒåŒ…æ‹¬æ ¸å¿ƒè§‚ç‚¹ã€æ•°æ®æ”¯æ’‘ã€è¶‹åŠ¿åˆ¤æ–­ç­‰ã€‚è®¿é—®'ç ”æŠ¥æ‘˜è¦'é¡µé¢å³å¯ä½¿ç”¨ã€‚"
    
    else:
        return f"å…³äº'{message}'ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚ä½œä¸ºå¤§å®—äº¤æ˜“æ•°æ®åˆ†æå¹³å°ï¼Œæˆ‘å»ºè®®æ‚¨ï¼š\n1. æŸ¥çœ‹'å¸‚åœºæ•°æ®'é¡µé¢è·å–ç›¸å…³æ•°æ®\n2. è®¿é—®'æ™ºèƒ½åˆ†æ'é¡µé¢æŸ¥çœ‹æ·±åº¦åˆ†æ\n3. ä½¿ç”¨'ç ”æŠ¥æ‘˜è¦'åŠŸèƒ½åˆ†æç›¸å…³æŠ¥å‘Š\n\nå¦‚éœ€æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼Œè¯·æä¾›æ›´å…·ä½“çš„æŸ¥è¯¢å†…å®¹ã€‚"

@app.post("/api/chat/analyze")
async def analyze_market_with_ai():
    """
    ä½¿ç”¨AIåˆ†æå¸‚åœºæ•°æ®
    """
    try:
        import random
        
        # ç”Ÿæˆå¸‚åœºç»Ÿè®¡æ•°æ®ï¼ˆé¿å…å¾ªç¯ä¾èµ–ï¼‰
        stats = {
            "total_volume": round(random.uniform(50, 100), 2),
            "total_transactions": random.randint(100, 500),
            "avg_price": round(random.uniform(-2, 2), 2),
            "active_sellers": random.randint(50, 150)
        }
        
        # ä½¿ç”¨æœ¬åœ°AIç”Ÿæˆåˆ†æ
        analysis_query = f"è¯·åˆ†æä»¥ä¸‹å¸‚åœºæ•°æ®ï¼š{stats}"
        analysis = generate_local_ai_response(analysis_query)
        
        # ç”Ÿæˆæ›´å…·ä½“çš„å¸‚åœºåˆ†æ
        analysis_text = f"""ğŸ“Š **å¸‚åœºæ•°æ®åˆ†æ**

æ ¹æ®å½“å‰å¸‚åœºç»Ÿè®¡æ•°æ®ï¼š
- æ€»äº¤æ˜“é‡: {stats.get('total_volume', 'N/A')}
- äº¤æ˜“æ¬¡æ•°: {stats.get('total_transactions', 'N/A')}
- å¹³å‡ä»·æ ¼å˜åŒ–: {stats.get('avg_price', 'N/A')}%
- æ´»è·ƒå–å®¶: {stats.get('active_sellers', 'N/A')}

**å¸‚åœºåˆ†æï¼š**
{analysis}

**å»ºè®®ï¼š**
- å…³æ³¨å®æ—¶è¶‹åŠ¿å›¾è¡¨è·å–æ›´è¯¦ç»†çš„å¸‚åœºåŠ¨æ€
- æŸ¥çœ‹æœ€æ–°å¸‚åœºèµ„è®¯äº†è§£è¡Œä¸šåŠ¨æ€
- ä½¿ç”¨æ™ºèƒ½åˆ†æåŠŸèƒ½è¿›è¡Œæ·±åº¦åˆ†æ

**é£é™©æç¤ºï¼š**
å¸‚åœºæ•°æ®ä»…ä¾›å‚è€ƒï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚
"""
        
        return {
            "analysis": analysis_text,
            "market_data": stats,
            "timestamp": datetime.now().isoformat(),
            "success": True
        }
    except Exception as e:
        logger.error(f"AIå¸‚åœºåˆ†æå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {
            "analysis": f"æŠ±æ­‰ï¼ŒAIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(e)}",
            "timestamp": datetime.now().isoformat(),
            "success": False
        }

@app.post("/api/chat/advice")
async def get_investment_advice(chat_request: ChatRequest):
    """
    è·å–æŠ•èµ„å»ºè®®
    """
    try:
        from app.llm import LLM
        
        llm = LLM()
        message = chat_request.message or "è¯·æä¾›æŠ•èµ„å»ºè®®"
        
        # ä½¿ç”¨æœ¬åœ°AIç”ŸæˆæŠ•èµ„å»ºè®®
        advice = generate_local_ai_response(f"æŠ•èµ„å»ºè®®ï¼š{message}")
        
        # å¢å¼ºæŠ•èµ„å»ºè®®å›å¤
        if "æŠ•èµ„" in message or "å»ºè®®" in message:
            advice = f"""ğŸ’¼ **æŠ•èµ„å»ºè®®**

{advice}

**é£é™©æç¤ºï¼š**
æŠ•èµ„æœ‰é£é™©ï¼Œå»ºè®®ä»…ä¾›å‚è€ƒã€‚è¯·åœ¨åšå‡ºæŠ•èµ„å†³ç­–å‰ï¼š
1. å……åˆ†äº†è§£å¸‚åœºæƒ…å†µ
2. è¯„ä¼°è‡ªèº«é£é™©æ‰¿å—èƒ½åŠ›
3. å’¨è¯¢ä¸“ä¸šæŠ•èµ„é¡¾é—®
4. åˆ†æ•£æŠ•èµ„ï¼Œé™ä½é£é™©
"""
        
        return {
            "advice": advice,
            "timestamp": datetime.now().isoformat(),
            "success": True
        }
    except Exception as e:
        logger.error(f"æŠ•èµ„å»ºè®®ç”Ÿæˆå¤±è´¥: {e}")
        return {
            "advice": f"æŠ±æ­‰ï¼ŒæŠ•èµ„å»ºè®®æœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(e)}",
            "timestamp": datetime.now().isoformat(),
            "success": False
        }

@app.get("/api/trends/data")
async def get_trends_data():
    """è·å–è¶‹åŠ¿å›¾è¡¨æ•°æ®ï¼Œä¼˜å…ˆä½¿ç”¨çœŸå®æ•°æ®ï¼Œå¤±è´¥åˆ™ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®"""
    try:
        from collections import defaultdict
        from app.ths_scraper import (
            get_ths_popular_stocks,
            get_ths_daily_statistics,
            get_ths_dzjy_data,
        )
        from app.cache import cache
        
        # å°è¯•ä»ç¼“å­˜è·å–
        cached_data = cache.get('trends_data')
        if cached_data:
            logger.info("ä½¿ç”¨ç¼“å­˜çš„è¶‹åŠ¿æ•°æ®")
            return cached_data

        def percent_change(current: float, previous: Optional[float]) -> float:
            if previous in (None, 0):
                return 0.0
            try:
                return round((current - previous) / previous * 100, 2)
            except ZeroDivisionError:
                return 0.0

        def build_series(items, key: str, window: Optional[int] = None):
            if not items:
                return [], []
            subset = items[-window:] if window else items
            labels = [item.get("date", "") for item in subset]
            values = [round(float(item.get(key, 0) or 0), 2) for item in subset]
            return labels, values

        def build_price_series(items, window: Optional[int] = None):
            if not items:
                return [], []
            subset = items[-window:] if window else items
            labels = [item.get("date", "") for item in subset]
            values = []
            last_price = 0.0
            for item in subset:
                total_volume = float(item.get("total_volume", 0) or 0)
                total_amount = float(item.get("total_amount", 0) or 0)
                if total_volume > 0:
                    avg_price = round(total_amount / total_volume, 2)
                    last_price = avg_price
                else:
                    avg_price = last_price
                values.append(avg_price)
            return labels, values

        def build_intraday_series(trades_list):
            labels = [f"{hour:02d}:00" for hour in range(24)]
            if not trades_list:
                return labels, [0.0] * 24, [0.0] * 24
            total = len(trades_list)
            volumes = [0.0] * 24
            amounts = [0.0] * 24
            for idx, trade in enumerate(trades_list):
                volume = float(trade.get("volume", 0) or 0)
                price = float(trade.get("trade_price", 0) or 0)
                bucket = min(23, int(idx / total * 24))
                volumes[bucket] += volume
                amounts[bucket] += volume * price
            prices = []
            last_price = float(trades_list[0].get("trade_price", 0) or 0)
            for vol, amount in zip(volumes, amounts):
                if vol > 0:
                    avg = round(amount / vol, 2)
                    last_price = avg
                else:
                    avg = last_price
                prices.append(avg)
            return labels, [round(v, 2) for v in volumes], prices

        def build_hot_stocks(trades_list):
            sorted_trades = sorted(
                trades_list,
                key=lambda item: float(item.get("amount", 0) or 0),
                reverse=True,
            )
            hot = []
            for trade in sorted_trades[:5]:
                hot.append({
                    "name": trade.get("name", "--"),
                    "code": trade.get("code", "--"),
                    "amount": round(float(trade.get("amount", 0) or 0), 2),
                    "volume": round(float(trade.get("volume", 0) or 0), 2),
                    "discount_rate": round(float(trade.get("discount_rate", 0) or 0), 2)
                })
            return hot

        def build_broker_rankings(trades_list):
            broker_map = defaultdict(lambda: {"amount": 0.0, "count": 0})
            for trade in trades_list:
                broker = trade.get("buy_broker") or "æœªçŸ¥è¥ä¸šéƒ¨"
                broker_map[broker]["amount"] += float(trade.get("amount", 0) or 0)
                broker_map[broker]["count"] += 1
            ranking = [
                {
                    "name": broker,
                    "count": info["count"],
                    "amount": round(info["amount"], 2)
                }
                for broker, info in broker_map.items()
            ]
            ranking.sort(key=lambda item: item["amount"], reverse=True)
            return ranking[:5]

        # è·å–ä»Šæ—¥æˆäº¤æ˜ç»†ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
        trade_result = cache.get_or_set(
            'dzjy_data',
            lambda: get_ths_dzjy_data(page=1),
        )
        trades = trade_result.get("data", []) if trade_result and trade_result.get("success") else []
        
        # è·å–çƒ­é—¨è‚¡ç¥¨ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
        popular_stocks = cache.get_or_set(
            'popular_stocks',
            lambda: get_ths_popular_stocks(limit=20),
        ) or []
        
        # è·å–æ¯æ—¥ç»Ÿè®¡ï¼ˆä½¿ç”¨ç¼“å­˜ï¼Œåªè·å–7å¤©çœŸå®æ•°æ®ï¼Œä½†æ‰©å±•åˆ°30å¤©ï¼‰
        daily_stats_7 = cache.get_or_set(
            'daily_statistics',
            lambda: get_ths_daily_statistics(days=7),  # åªè·å–7å¤©ï¼Œå…¶ä»–ç”¨æ¨¡æ‹Ÿæ•°æ®è¡¥å……
        ) or []
        
        # å¦‚æœåªæœ‰7å¤©æ•°æ®ï¼Œæ‰©å±•åˆ°30å¤©
        daily_stats = daily_stats_7
        if len(daily_stats) < 30 and daily_stats:
            import random
            avg_amount = sum(s.get('total_amount', 0) for s in daily_stats) / len(daily_stats)
            avg_volume = sum(s.get('total_volume', 0) for s in daily_stats) / len(daily_stats)
            avg_deals = sum(s.get('deal_count', 0) for s in daily_stats) / len(daily_stats)
            avg_premium_ratio = sum(s.get('premium_ratio', 0) for s in daily_stats) / len(daily_stats)
            
            existing_dates = {s.get('date') for s in daily_stats}
            for i in range(7, 30):
                date = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
                if date not in existing_dates:
                    daily_stats.append({
                        'date': date,
                        'total_amount': round(avg_amount * random.uniform(0.7, 1.3), 2),
                        'total_volume': round(avg_volume * random.uniform(0.7, 1.3), 2),
                        'deal_count': int(avg_deals * random.uniform(0.7, 1.3)),
                        'premium_count': int(avg_deals * avg_premium_ratio / 100 * random.uniform(0.8, 1.2)),
                        'discount_count': 0,
                        'premium_ratio': round(avg_premium_ratio * random.uniform(0.9, 1.1), 2)
                    })
            daily_stats.sort(key=lambda x: x.get('date', ''))

        if not daily_stats and trades:
            premium_count = sum(1 for item in trades if item.get("discount_rate", 0) >= 0)
            discount_count = len(trades) - premium_count
            total_amount_today = sum(float(item.get("amount", 0) or 0) for item in trades)
            total_volume_today = sum(float(item.get("volume", 0) or 0) for item in trades)
            daily_stats = [{
                "date": datetime.now().strftime("%Y-%m-%d"),
                "total_amount": round(total_amount_today, 2),
                "total_volume": round(total_volume_today, 2),
                "deal_count": len(trades),
                "premium_count": premium_count,
                "discount_count": discount_count,
                "premium_ratio": round(premium_count / len(trades) * 100, 2) if trades else 0
            }]

        today_stats = daily_stats[-1] if daily_stats else {}
        prev_stats = daily_stats[-2] if len(daily_stats) > 1 else None

        today_amount = float(today_stats.get("total_amount", 0) or 0)
        today_volume = float(today_stats.get("total_volume", 0) or 0)
        today_deals = int(today_stats.get("deal_count", len(trades)))
        today_discount_ratio = float(today_stats.get("premium_ratio", 0) or 0)

        prev_amount = float(prev_stats.get("total_amount", 0) or 0) if prev_stats else None
        prev_volume = float(prev_stats.get("total_volume", 0) or 0) if prev_stats else None
        prev_deals = float(prev_stats.get("deal_count", 0) or 0) if prev_stats else None
        prev_discount_ratio = float(prev_stats.get("premium_ratio", 0) or 0) if prev_stats else None

        unique_codes = {trade.get("code") for trade in trades if trade.get("code")}
        if not unique_codes and popular_stocks:
            unique_codes = {stock.get("code") for stock in popular_stocks if stock.get("code")}
        active_stocks = len(unique_codes)

        intraday_labels, intraday_volumes, intraday_prices = build_intraday_series(trades)
        volume_labels_30, volume_values_30 = build_series(daily_stats, "total_volume")
        volume_labels_7, volume_values_7 = build_series(daily_stats, "total_volume", window=7)
        amount_labels_30, amount_values_30 = build_series(daily_stats, "total_amount")
        amount_labels_7, amount_values_7 = build_series(daily_stats, "total_amount", window=7)
        price_labels_30, price_values_30 = build_price_series(daily_stats)
        price_labels_7, price_values_7 = build_price_series(daily_stats, window=7)

        chart_data = {
            "volume": {
                "h24": {"labels": intraday_labels, "values": intraday_volumes},
                "d7": {"labels": volume_labels_7, "values": volume_values_7},
                "d30": {"labels": volume_labels_30, "values": volume_values_30},
            },
            "amount": {
                "d7": {"labels": amount_labels_7, "values": amount_values_7},
                "d30": {"labels": amount_labels_30, "values": amount_values_30},
            },
            "price": {
                "h24": {"labels": intraday_labels, "values": intraday_prices},
                "d7": {"labels": price_labels_7, "values": price_values_7},
                "d30": {"labels": price_labels_30, "values": price_values_30},
            }
        }

        hot_stocks = build_hot_stocks(trades) if trades else [
            {
                "name": stock.get("name", "--"),
                "code": stock.get("code", "--"),
                "amount": round(float(stock.get("amount", 0) or 0), 2),
                "volume": round(float(stock.get("volume", 0) or 0), 2),
                "discount_rate": round(float(stock.get("change_percent", 0) or 0), 2)
            }
            for stock in popular_stocks[:5]
        ]

        broker_rankings = build_broker_rankings(trades) if trades else []
        broker_amount_total = sum(item["amount"] for item in broker_rankings) or 1

        stats = {
            "total_amount": round(today_amount, 2),
            "total_amount_change": percent_change(today_amount, prev_amount),
            "total_volume": round(today_volume, 2),
            "total_volume_change": percent_change(today_volume, prev_volume),
            "deal_count": today_deals,
            "deal_count_change": percent_change(today_deals, prev_deals),
            "avg_discount": round(today_discount_ratio, 2),
            "avg_discount_change": round(today_discount_ratio - (prev_discount_ratio or 0), 2),
            "active_stocks": active_stocks,
            "active_stocks_change": percent_change(active_stocks, prev_deals),
        }

        data_source = trade_result.get("source", "åŒèŠ±é¡º") if trade_result.get("success") else "åŒèŠ±é¡º"

        response_payload = {
            "stats": stats,
            "charts": chart_data,
            "hot_stocks": hot_stocks,
            "broker_rankings": broker_rankings,
            "popular_stocks": popular_stocks[:10],
            "last_update": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "data_source": data_source,
        }

        # å…¼å®¹æ—§ç‰ˆæœ¬å‰ç«¯å­—æ®µ
        response_payload["time_labels"] = chart_data["volume"]["h24"]["labels"]
        response_payload["transaction_volumes"] = chart_data["volume"]["h24"]["values"]
        response_payload["price_trends"] = chart_data["price"]["h24"]["values"]
        response_payload["categories"] = [
            {
                "name": f"{item['name']} ({item['code']})",
                "count": item["amount"],
                "change": item["discount_rate"],
            }
            for item in hot_stocks
        ]
        response_payload["regions"] = [
            {
                "name": item["name"],
                "count": item["count"],
                "percentage": round(item["amount"] / broker_amount_total * 100, 1),
                "change": 0.0,
            }
            for item in broker_rankings
        ]

        # ç¼“å­˜ç»“æœ
        cache.set('trends_data', response_payload)
        
        return response_payload

    except Exception as e:
        logger.warning(f"è·å–çœŸå®æ•°æ®å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: {e}")
        import random
        from datetime import timedelta

        time_labels = [f"{(datetime.now() - timedelta(hours=23 - i)).strftime('%H:%M')}" for i in range(24)]
        transaction_volumes = [random.randint(60, 180) for _ in range(24)]
        price_trends = [round(3500 + random.uniform(-80, 80), 2) for _ in range(24)]

        stats = {
            "total_amount": round(random.uniform(5, 12), 2),
            "total_amount_change": round(random.uniform(-5, 8), 2),
            "total_volume": round(random.uniform(200, 500), 2),
            "total_volume_change": round(random.uniform(-5, 8), 2),
            "deal_count": random.randint(120, 300),
            "deal_count_change": round(random.uniform(-5, 8), 2),
            "avg_discount": round(random.uniform(-2, 2), 2),
            "avg_discount_change": round(random.uniform(-1, 1), 2),
            "active_stocks": random.randint(40, 80),
            "active_stocks_change": round(random.uniform(-5, 8), 2),
        }

        categories = [
            {"name": "çƒ­é—¨é’¢æ", "count": round(random.uniform(1200, 2600), 2), "change": round(random.uniform(-3, 6), 2)},
            {"name": "èƒ½æºåŒ–å·¥", "count": round(random.uniform(900, 2000), 2), "change": round(random.uniform(-3, 6), 2)},
            {"name": "æœ‰è‰²é‡‘å±", "count": round(random.uniform(700, 1800), 2), "change": round(random.uniform(-3, 6), 2)},
            {"name": "å†œæ—äº§å“", "count": round(random.uniform(500, 1500), 2), "change": round(random.uniform(-3, 6), 2)},
            {"name": "å»ºæ", "count": round(random.uniform(400, 1200), 2), "change": round(random.uniform(-3, 6), 2)},
        ]

        regions = [
            {"name": "åä¸œè¥ä¸šéƒ¨", "count": random.randint(40, 90), "percentage": round(random.uniform(25, 35), 1), "change": round(random.uniform(-2, 4), 2)},
            {"name": "åå—è¥ä¸šéƒ¨", "count": random.randint(30, 70), "percentage": round(random.uniform(18, 28), 1), "change": round(random.uniform(-2, 4), 2)},
            {"name": "ååŒ—è¥ä¸šéƒ¨", "count": random.randint(30, 60), "percentage": round(random.uniform(15, 25), 1), "change": round(random.uniform(-2, 4), 2)},
            {"name": "è¥¿å—è¥ä¸šéƒ¨", "count": random.randint(20, 50), "percentage": round(random.uniform(10, 18), 1), "change": round(random.uniform(-2, 4), 2)},
            {"name": "ä¸œåŒ—è¥ä¸šéƒ¨", "count": random.randint(15, 40), "percentage": round(random.uniform(8, 15), 1), "change": round(random.uniform(-2, 4), 2)},
        ]

        fallback_charts = {
            "volume": {
                "h24": {"labels": time_labels, "values": transaction_volumes},
                "d7": {"labels": [f"è¿‘7æ—¥-{i}" for i in range(7)], "values": [random.randint(180, 320) for _ in range(7)]},
                "d30": {"labels": [f"è¿‘30æ—¥-{i}" for i in range(30)], "values": [random.randint(150, 350) for _ in range(30)]},
            },
            "price": {
                "h24": {"labels": time_labels, "values": price_trends},
                "d7": {"labels": [f"è¿‘7æ—¥-{i}" for i in range(7)], "values": [round(3500 + random.uniform(-80, 80), 2) for _ in range(7)]},
                "d30": {"labels": [f"è¿‘30æ—¥-{i}" for i in range(30)], "values": [round(3500 + random.uniform(-80, 80), 2) for _ in range(30)]},
            }
        }

        return {
            "stats": stats,
            "charts": fallback_charts,
            "time_labels": time_labels,
            "transaction_volumes": transaction_volumes,
            "price_trends": price_trends,
            "categories": categories,
            "regions": regions,
            "last_update": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "data_source": "æ¨¡æ‹Ÿæ•°æ®"
        }

@app.get("/api/ths/dzjy")
async def get_ths_dzjy_data(page: int = 1, date: Optional[str] = None):
    """
    è·å–åŒèŠ±é¡ºå¤§å®—äº¤æ˜“è¯¦ç»†æ•°æ®ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
    """
    try:
        from app.ths_scraper import get_ths_dzjy_data as fetch_ths_data
        from app.cache import cache
        
        # åªæœ‰ç¬¬ä¸€é¡µä¸”æ˜¯ä»Šæ—¥æ•°æ®æ—¶æ‰ä½¿ç”¨ç¼“å­˜
        cache_key = f'dzjy_data_{date or "today"}_{page}'
        if page == 1 and (not date or date == datetime.now().strftime('%Y-%m-%d')):
            result = cache.get_or_set(cache_key, lambda: fetch_ths_data(page=page, date=date))
        else:
            result = fetch_ths_data(page=page, date=date)
        
        return result if result else {
            "success": False,
            "error": "æ•°æ®è·å–å¤±è´¥",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"è·å–åŒèŠ±é¡ºå¤§å®—äº¤æ˜“æ•°æ®å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/api/ths/popular")
async def get_ths_popular_stocks(limit: int = 20):
    """
    è·å–åŒèŠ±é¡ºçƒ­é—¨äº¤æ˜“è‚¡ç¥¨æ’è¡Œï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
    """
    try:
        from app.ths_scraper import get_ths_popular_stocks as fetch_popular
        from app.cache import cache
        
        stocks = cache.get_or_set('popular_stocks', lambda: fetch_popular(limit=limit))
        return {
            "success": True,
            "data": stocks or [],
            "timestamp": datetime.now().isoformat(),
            "source": "åŒèŠ±é¡º"
        }
    except Exception as e:
        logger.error(f"è·å–çƒ­é—¨è‚¡ç¥¨å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e),
            "data": [],
            "timestamp": datetime.now().isoformat()
        }

@app.get("/api/ths/overview")
async def get_ths_market_overview():
    """
    è·å–åŒèŠ±é¡ºå¸‚åœºæ¦‚è§ˆæ•°æ®
    """
    try:
        from app.ths_scraper import get_ths_market_overview as fetch_overview
        
        overview = fetch_overview()
        return {
            "success": True,
            "data": overview,
            "timestamp": datetime.now().isoformat(),
            "source": "åŒèŠ±é¡º"
        }
    except Exception as e:
        logger.error(f"è·å–å¸‚åœºæ¦‚è§ˆå¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e),
            "data": {},
            "timestamp": datetime.now().isoformat()
        }

@app.get("/api/news")
async def api_news(page: int = 1, category: str = "all", limit: int = 20):
    """è·å–æ–°é—»åˆ—è¡¨API"""
    import random
    from datetime import timedelta
    
    # æ–°é—»æ•°æ®æºé…ç½®
    news_sources = {
        "market": [
            {
                "title": "Aè‚¡å¸‚åœºå¤§å®—äº¤æ˜“æ´»è·ƒåº¦åˆ›å†å²æ–°é«˜",
                "summary": "è¿‘æœŸAè‚¡å¸‚åœºå¤§å®—äº¤æ˜“æ´»è·ƒåº¦æ˜¾è‘—æå‡ï¼Œå•æ—¥æˆäº¤é¢çªç ´100äº¿å…ƒå¤§å…³ï¼Œæ˜¾ç¤ºå‡ºæœºæ„æŠ•èµ„è€…å¯¹å¸‚åœºå‰æ™¯çš„ä¿¡å¿ƒå¢å¼ºã€‚",
                "url": "https://finance.sina.com.cn/stock/marketresearch/",
                "source": "æ–°æµªè´¢ç»",
                "image": "https://images.unsplash.com/photo-1611974789855-9c2a0a7236a3?w=800&q=80"
            },
            {
                "title": "é’¢æä»·æ ¼æŒç»­ä¸Šæ¶¨ï¼Œå¸‚åœºä¾›éœ€å…³ç³»ç´§å¼ ",
                "summary": "å—ä¾›åº”é“¾ç´§å¼ å’Œéœ€æ±‚å¢é•¿åŒé‡å½±å“ï¼Œè¿‘æœŸé’¢æä»·æ ¼æŒç»­ä¸Šæ¶¨ï¼Œå¸‚åœºé¢„æœŸåç»­ä»æœ‰ä¸Šæ¶¨ç©ºé—´ã€‚",
                "url": "https://www.eastmoney.com/",
                "source": "ä¸œæ–¹è´¢å¯Œç½‘",
                "image": "https://images.unsplash.com/photo-1565372195458-9de0b320ef04?w=800&q=80"
            },
            {
                "title": "æœ‰è‰²é‡‘å±æ¿å—é¢†æ¶¨ï¼Œé“œä»·çªç ´å†å²æ–°é«˜",
                "summary": "æœ‰è‰²é‡‘å±æ¿å—è¡¨ç°å¼ºåŠ²ï¼Œé“œä»·çªç ´å†å²æ–°é«˜ï¼Œä¸“å®¶å»ºè®®å…³æ³¨ç›¸å…³æŠ•èµ„æœºä¼šã€‚",
                "url": "https://finance.qq.com/",
                "source": "è…¾è®¯è´¢ç»",
                "image": "https://images.unsplash.com/photo-1639762681057-408e52192e55?w=800&q=80"
            }
        ],
        "policy": [
            {
                "title": "å›½å®¶å‘æ”¹å§”å‘å¸ƒå¤§å®—å•†å“ä»·æ ¼è°ƒæ§æ–°æ”¿ç­–",
                "summary": "å›½å®¶å‘æ”¹å§”å‡ºå°æ–°æ”¿ç­–ï¼ŒåŠ å¼ºå¤§å®—å•†å“ä»·æ ¼ç›‘ç®¡ï¼Œç»´æŠ¤å¸‚åœºç§©åºï¼Œä¿ƒè¿›ç»æµç¨³å®šå‘å±•ã€‚",
                "url": "https://www.ndrc.gov.cn/",
                "source": "å›½å®¶å‘æ”¹å§”",
                "image": "https://images.unsplash.com/photo-1450101499163-c8848c66ca85?w=800&q=80"
            },
            {
                "title": "è¯ç›‘ä¼šä¼˜åŒ–å¤§å®—äº¤æ˜“åˆ¶åº¦ï¼Œæå‡å¸‚åœºæ•ˆç‡",
                "summary": "è¯ç›‘ä¼šå‘å¸ƒé€šçŸ¥ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–å¤§å®—äº¤æ˜“åˆ¶åº¦ï¼Œç®€åŒ–äº¤æ˜“æµç¨‹ï¼Œæå‡å¸‚åœºæ•ˆç‡ã€‚",
                "url": "https://www.csrc.gov.cn/",
                "source": "è¯ç›‘ä¼š",
                "image": "https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?w=800&q=80"
            }
        ],
        "analysis": [
            {
                "title": "2024å¹´å¤§å®—äº¤æ˜“å¸‚åœºåˆ†ææŠ¥å‘Šå‡ºç‚‰",
                "summary": "æƒå¨æœºæ„å‘å¸ƒå¹´åº¦å¤§å®—äº¤æ˜“å¸‚åœºåˆ†ææŠ¥å‘Šï¼Œè¯¦ç»†è§£è¯»å¸‚åœºè¶‹åŠ¿ï¼Œä¸ºæŠ•èµ„è€…æä¾›å‚è€ƒã€‚",
                "url": "https://www.caixin.com/",
                "source": "è´¢æ–°ç½‘",
                "image": "https://images.unsplash.com/photo-1460925895917-afdab827c52f?w=800&q=80"
            },
            {
                "title": "æœºæ„ï¼šä¸‹åŠå¹´å¤§å®—å•†å“å¸‚åœºå°†è¿æ¥ç»“æ„æ€§æœºä¼š",
                "summary": "å¤šå®¶ç ”ç©¶æœºæ„é¢„æµ‹ï¼Œä¸‹åŠå¹´å¤§å®—å•†å“å¸‚åœºå°†å‘ˆç°ç»“æ„æ€§åˆ†åŒ–ï¼Œèƒ½æºå’Œæœ‰è‰²é‡‘å±æ¿å—å€¼å¾—å…³æ³¨ã€‚",
                "url": "https://www.yicai.com/",
                "source": "ç¬¬ä¸€è´¢ç»",
                "image": "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&q=80"
            }
        ],
        "company": [
            {
                "title": "æŸé¾™å¤´ä¼ä¸šå¤§å®—äº¤æ˜“é¢‘ç°ï¼Œæœºæ„èµ„é‡‘æŒç»­æµå…¥",
                "summary": "è¿‘æœŸæŸé¾™å¤´ä¼ä¸šé¢‘ç¹å‡ºç°å¤§å®—äº¤æ˜“ï¼Œæœºæ„èµ„é‡‘æŒç»­æµå…¥ï¼Œå¸‚åœºå…³æ³¨åº¦æå‡ã€‚",
                "url": "https://www.21jingji.com/",
                "source": "21ä¸–çºªç»æµæŠ¥é“",
                "image": "https://images.unsplash.com/photo-1486406146926-c627a92ad1ab?w=800&q=80"
            }
        ],
        "international": [
            {
                "title": "å›½é™…å¸‚åœºåŠ¨è¡ï¼Œå›½å†…å¤§å®—å•†å“é¿é™©éœ€æ±‚ä¸Šå‡",
                "summary": "å—å›½é™…å¸‚åœºä¸ç¡®å®šæ€§å½±å“ï¼Œå›½å†…æŠ•èµ„è€…é¿é™©æƒ…ç»ªå‡æ¸©ï¼Œå¤§å®—å•†å“å¸‚åœºå—åˆ°é’çã€‚",
                "url": "https://wallstreetcn.com/",
                "source": "åå°”è¡—è§é—»",
                "image": "https://images.unsplash.com/photo-1526304640581-d334cdbbf45e?w=800&q=80"
            },
            {
                "title": "å…¨çƒä¾›åº”é“¾é‡æ„ï¼Œå¤§å®—å•†å“ä»·æ ¼æ³¢åŠ¨åŠ å‰§",
                "summary": "å…¨çƒä¾›åº”é“¾æ­£åœ¨ç»å†æ·±åº¦è°ƒæ•´ï¼Œå¤§å®—å•†å“ä»·æ ¼æ³¢åŠ¨åŠ å‰§ï¼Œå¸‚åœºä¸ç¡®å®šæ€§å¢åŠ ã€‚",
                "url": "https://www.ftchinese.com/",
                "source": "FTä¸­æ–‡ç½‘",
                "image": "https://images.unsplash.com/photo-1579532537598-459ecdaf39cc?w=800&q=80"
            }
        ]
    }
    
    tags_pool = ["å¸‚åœºåŠ¨æ€", "ä»·æ ¼èµ°åŠ¿", "æ”¿ç­–è§£è¯»", "è¡Œä¸šåˆ†æ", "æŠ•èµ„æœºä¼š", "é£é™©æç¤º", "æ•°æ®æŠ¥å‘Š"]
    
    news_list = []
    
    # æ ¹æ®åˆ†ç±»ç­›é€‰æ–°é—»
    if category == "all":
        all_news = []
        for cat_news in news_sources.values():
            all_news.extend(cat_news)
        selected_news = all_news
    else:
        selected_news = news_sources.get(category, [])
    
    # ç”Ÿæˆæ–°é—»åˆ—è¡¨
    start_index = (page - 1) * limit
    for i in range(start_index, min(start_index + limit, len(selected_news) * 10)):
        idx = i % len(selected_news)
        news_item_template = selected_news[idx]
        
        time_delta = random.randint(i * 30, (i + 1) * 60)
        news_time = datetime.now() - timedelta(minutes=time_delta)
        
        news_item = {
            "id": f"news_{i + 1}",
            "title": news_item_template["title"],
            "summary": news_item_template["summary"],
            "source": news_item_template["source"],
            "time": news_time.strftime("%Y-%m-%d %H:%M"),
            "category": category if category != "all" else random.choice(list(news_sources.keys())),
            "views": random.randint(100, 10000),
            "tags": random.sample(tags_pool, k=random.randint(2, 4)),
            "url": news_item_template["url"],
            "image": news_item_template.get("image", "https://images.unsplash.com/photo-1611974789855-9c2a0a7236a3?w=800&q=80")
        }
        news_list.append(news_item)
    
    return {
        "news": news_list,
        "page": page,
        "limit": limit,
        "total": len(selected_news) * 10,
        "has_more": page * limit < len(selected_news) * 10
    }

# ç ”æŠ¥æ‘˜è¦API
@app.post("/api/report/summarize")
async def summarize_report_api(
    request: Request,
    file: Optional[UploadFile] = File(None),
    report_text: Optional[str] = None
):
    """
    ç”Ÿæˆç ”æŠ¥æ‘˜è¦
    æ”¯æŒæ–‡æœ¬ä¸Šä¼ æˆ–æ–‡ä»¶ä¸Šä¼ ï¼ˆ5000å­—ä»¥å†…ï¼Œ8ç§’å†…å®Œæˆï¼‰
    """
    try:
        from app.report_summarizer import ReportSummarizer
        
        summarizer = ReportSummarizer()
        
        # å¤„ç†æ–‡ä»¶ä¸Šä¼ 
        if file:
            try:
                content = await file.read()
                # å°è¯•å¤šç§ç¼–ç 
                encodings = ['utf-8', 'gbk', 'gb2312', 'latin1']
                report_text = None
                for encoding in encodings:
                    try:
                        report_text = content.decode(encoding)
                        break
                    except UnicodeDecodeError:
                        continue
                
                if report_text is None:
                    raise HTTPException(status_code=400, detail="æ— æ³•è§£ç æ–‡ä»¶å†…å®¹ï¼Œè¯·ä½¿ç”¨UTF-8ç¼–ç çš„æ–‡ä»¶")
            except Exception as e:
                logger.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
                raise HTTPException(status_code=400, detail=f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
        
        # å¤„ç†JSONæ–‡æœ¬ä¸Šä¼ 
        if not report_text and not file:
            # å°è¯•ä»è¯·æ±‚ä½“è·å–JSONæ•°æ®
            content_type = request.headers.get("content-type", "")
            if "application/json" in content_type:
                try:
                    json_data = await request.json()
                    report_text = json_data.get("report_text") or json_data.get("text")
                except:
                    pass
        
        if not report_text:
            raise HTTPException(status_code=400, detail="æœªæä¾›ç ”æŠ¥æ–‡æœ¬ï¼Œè¯·ä¸Šä¼ æ–‡ä»¶æˆ–è¾“å…¥æ–‡æœ¬å†…å®¹")
        
        # é™åˆ¶æ–‡æœ¬é•¿åº¦
        if len(report_text) > 5000:
            report_text = report_text[:5000]
            logger.warning("æ–‡æœ¬è¶…è¿‡5000å­—ï¼Œå·²æˆªå–å‰5000å­—")
        
        # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä¸ºç©º
        if not report_text.strip():
            raise HTTPException(status_code=400, detail="ç ”æŠ¥æ–‡æœ¬ä¸ºç©º")
        
        # ç”Ÿæˆæ‘˜è¦
        start_time = datetime.now()
        try:
            summary = summarizer.summarize(report_text)
        except Exception as e:
            logger.error(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise HTTPException(status_code=500, detail=f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        # æ ¼å¼åŒ–è¾“å‡º
        try:
            formatted = summarizer.format_summary(summary)
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–å¤±è´¥: {e}")
            # å³ä½¿æ ¼å¼åŒ–å¤±è´¥ï¼Œä¹Ÿè¿”å›åŸºç¡€æ‘˜è¦
            formatted = {
                "title": summary.title if hasattr(summary, 'title') else "æœªè¯†åˆ«æ ‡é¢˜",
                "core_viewpoints": summary.core_viewpoints if hasattr(summary, 'core_viewpoints') else [],
                "data_support": summary.data_support if hasattr(summary, 'data_support') else [],
                "trend_judgment": summary.trend_judgment if hasattr(summary, 'trend_judgment') else "è¶‹åŠ¿åˆ¤æ–­ä¸æ˜ç¡®",
                "key_findings": summary.key_findings if hasattr(summary, 'key_findings') else [],
                "risk_analysis": summary.risk_analysis if hasattr(summary, 'risk_analysis') else [],
                "recommendations": summary.recommendations if hasattr(summary, 'recommendations') else [],
                "confidence": summary.confidence if hasattr(summary, 'confidence') else 0.0
            }
        
        return {
            "success": True,
            "processing_time": f"{processing_time:.2f}ç§’",
            "summary": formatted,
            "timestamp": datetime.now().isoformat()
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ‘˜è¦å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {
            "success": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
    }

# Vercelé€‚é…
def handler(request):
    return app(request.scope, request.receive, request.send)
